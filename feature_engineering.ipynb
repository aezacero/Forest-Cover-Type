{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a56d7f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_validate, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0602482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(X, y, model, cv=5):\n",
    "    '''\n",
    "    Train a model using cross-validation and display the confusion matrix.\n",
    "    '''\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    scores = cross_validate(model, X, y, cv=kf, scoring=['accuracy'])\n",
    "    y_pred = cross_val_predict(model, X, y, cv=kf)\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    # disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    # disp.plot()\n",
    "    # plt.show()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83d5713f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2161\n",
      "[LightGBM] [Info] Number of data points in the train set: 12096, number of used features: 44\n",
      "[LightGBM] [Info] Start training from score -1.943021\n",
      "[LightGBM] [Info] Start training from score -1.964602\n",
      "[LightGBM] [Info] Start training from score -1.927561\n",
      "[LightGBM] [Info] Start training from score -1.948228\n",
      "[LightGBM] [Info] Start training from score -1.957552\n",
      "[LightGBM] [Info] Start training from score -1.936120\n",
      "[LightGBM] [Info] Start training from score -1.944753\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 22\u001b[0m\n\u001b[1;32m     10\u001b[0m id_test \u001b[38;5;241m=\u001b[39m test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m model \u001b[38;5;241m=\u001b[39m LGBMClassifier(\n\u001b[1;32m     13\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[1;32m     14\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m training(X, y, model)\n",
      "Cell \u001b[0;32mIn[30], line 6\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(X, y, model, cv)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mTrain a model using cross-validation and display the confusion matrix.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      5\u001b[0m kf \u001b[38;5;241m=\u001b[39m KFold(n_splits\u001b[38;5;241m=\u001b[39mcv, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m scores \u001b[38;5;241m=\u001b[39m cross_validate(model, X, y, cv\u001b[38;5;241m=\u001b[39mkf, scoring\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      7\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m cross_val_predict(model, X, y, cv\u001b[38;5;241m=\u001b[39mkf)\n\u001b[1;32m      8\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y, y_pred)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/model_selection/_validation.py:411\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    410\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 411\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    412\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    413\u001b[0m         clone(estimator),\n\u001b[1;32m    414\u001b[0m         X,\n\u001b[1;32m    415\u001b[0m         y,\n\u001b[1;32m    416\u001b[0m         scorer\u001b[38;5;241m=\u001b[39mscorers,\n\u001b[1;32m    417\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    418\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    419\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    420\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    421\u001b[0m         fit_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit,\n\u001b[1;32m    422\u001b[0m         score_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mscorer\u001b[38;5;241m.\u001b[39mscore,\n\u001b[1;32m    423\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[1;32m    424\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    425\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[1;32m    426\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    427\u001b[0m     )\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m    429\u001b[0m )\n\u001b[1;32m    431\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/model_selection/_validation.py:866\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    864\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 866\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/lightgbm/sklearn.py:1560\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1557\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1558\u001b[0m             valid_sets\u001b[38;5;241m.\u001b[39mappend((valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y)))\n\u001b[0;32m-> 1560\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m   1561\u001b[0m     X,\n\u001b[1;32m   1562\u001b[0m     _y,\n\u001b[1;32m   1563\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1564\u001b[0m     init_score\u001b[38;5;241m=\u001b[39minit_score,\n\u001b[1;32m   1565\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39mvalid_sets,\n\u001b[1;32m   1566\u001b[0m     eval_names\u001b[38;5;241m=\u001b[39meval_names,\n\u001b[1;32m   1567\u001b[0m     eval_sample_weight\u001b[38;5;241m=\u001b[39meval_sample_weight,\n\u001b[1;32m   1568\u001b[0m     eval_class_weight\u001b[38;5;241m=\u001b[39meval_class_weight,\n\u001b[1;32m   1569\u001b[0m     eval_init_score\u001b[38;5;241m=\u001b[39meval_init_score,\n\u001b[1;32m   1570\u001b[0m     eval_metric\u001b[38;5;241m=\u001b[39meval_metric,\n\u001b[1;32m   1571\u001b[0m     feature_name\u001b[38;5;241m=\u001b[39mfeature_name,\n\u001b[1;32m   1572\u001b[0m     categorical_feature\u001b[38;5;241m=\u001b[39mcategorical_feature,\n\u001b[1;32m   1573\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m   1574\u001b[0m     init_model\u001b[38;5;241m=\u001b[39minit_model,\n\u001b[1;32m   1575\u001b[0m )\n\u001b[1;32m   1576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/lightgbm/sklearn.py:1049\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1046\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1047\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m-> 1049\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[1;32m   1050\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m   1051\u001b[0m     train_set\u001b[38;5;241m=\u001b[39mtrain_set,\n\u001b[1;32m   1052\u001b[0m     num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators,\n\u001b[1;32m   1053\u001b[0m     valid_sets\u001b[38;5;241m=\u001b[39mvalid_sets,\n\u001b[1;32m   1054\u001b[0m     valid_names\u001b[38;5;241m=\u001b[39meval_names,\n\u001b[1;32m   1055\u001b[0m     feval\u001b[38;5;241m=\u001b[39meval_metrics_callable,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m     init_model\u001b[38;5;241m=\u001b[39minit_model,\n\u001b[1;32m   1057\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m   1058\u001b[0m )\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mnum_feature()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/lightgbm/engine.py:322\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    311\u001b[0m     cb(\n\u001b[1;32m    312\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[1;32m    313\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    319\u001b[0m         )\n\u001b[1;32m    320\u001b[0m     )\n\u001b[0;32m--> 322\u001b[0m booster\u001b[38;5;241m.\u001b[39mupdate(fobj\u001b[38;5;241m=\u001b[39mfobj)\n\u001b[1;32m    324\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/lightgbm/basic.py:4155\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   4152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   4153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4154\u001b[0m _safe_call(\n\u001b[0;32m-> 4155\u001b[0m     _LIB\u001b[38;5;241m.\u001b[39mLGBM_BoosterUpdateOneIter(\n\u001b[1;32m   4156\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle,\n\u001b[1;32m   4157\u001b[0m         ctypes\u001b[38;5;241m.\u001b[39mbyref(is_finished),\n\u001b[1;32m   4158\u001b[0m     )\n\u001b[1;32m   4159\u001b[0m )\n\u001b[1;32m   4160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   4161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('Data/train.csv')\n",
    "test = pd.read_csv('Data/test-full.csv')\n",
    "X = train.drop(columns=['Id', 'Cover_Type'])\n",
    "\n",
    "X_test = test.drop(columns=['Id'])\n",
    "\n",
    "original_features = X.columns.tolist()\n",
    "y = train['Cover_Type']\n",
    "id = train['Id']\n",
    "id_test = test['Id']\n",
    "\n",
    "model = model = LGBMClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "training(X, y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cb3174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3080\n",
      "[LightGBM] [Info] Number of data points in the train set: 12096, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -1.943021\n",
      "[LightGBM] [Info] Start training from score -1.964602\n",
      "[LightGBM] [Info] Start training from score -1.927561\n",
      "[LightGBM] [Info] Start training from score -1.948228\n",
      "[LightGBM] [Info] Start training from score -1.957552\n",
      "[LightGBM] [Info] Start training from score -1.936120\n",
      "[LightGBM] [Info] Start training from score -1.944753\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3072\n",
      "[LightGBM] [Info] Number of data points in the train set: 12096, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -1.937267\n",
      "[LightGBM] [Info] Start training from score -1.933831\n",
      "[LightGBM] [Info] Start training from score -1.966373\n",
      "[LightGBM] [Info] Start training from score -1.955797\n",
      "[LightGBM] [Info] Start training from score -1.935547\n",
      "[LightGBM] [Info] Start training from score -1.947648\n",
      "[LightGBM] [Info] Start training from score -1.945332\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3070\n",
      "[LightGBM] [Info] Number of data points in the train set: 12096, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -1.953462\n",
      "[LightGBM] [Info] Start training from score -1.949969\n",
      "[LightGBM] [Info] Start training from score -1.958137\n",
      "[LightGBM] [Info] Start training from score -1.933259\n",
      "[LightGBM] [Info] Start training from score -1.947068\n",
      "[LightGBM] [Info] Start training from score -1.940140\n",
      "[LightGBM] [Info] Start training from score -1.939565\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007973 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3076\n",
      "[LightGBM] [Info] Number of data points in the train set: 12096, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -1.954629\n",
      "[LightGBM] [Info] Start training from score -1.948808\n",
      "[LightGBM] [Info] Start training from score -1.937267\n",
      "[LightGBM] [Info] Start training from score -1.937841\n",
      "[LightGBM] [Info] Start training from score -1.950551\n",
      "[LightGBM] [Info] Start training from score -1.939565\n",
      "[LightGBM] [Info] Start training from score -1.952879\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3075\n",
      "[LightGBM] [Info] Number of data points in the train set: 12096, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -1.941291\n",
      "[LightGBM] [Info] Start training from score -1.932688\n",
      "[LightGBM] [Info] Start training from score -1.940715\n",
      "[LightGBM] [Info] Start training from score -1.954629\n",
      "[LightGBM] [Info] Start training from score -1.938990\n",
      "[LightGBM] [Info] Start training from score -1.966373\n",
      "[LightGBM] [Info] Start training from score -1.947068\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3080\n",
      "[LightGBM] [Info] Number of data points in the train set: 12096, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -1.943021\n",
      "[LightGBM] [Info] Start training from score -1.964602\n",
      "[LightGBM] [Info] Start training from score -1.927561\n",
      "[LightGBM] [Info] Start training from score -1.948228\n",
      "[LightGBM] [Info] Start training from score -1.957552\n",
      "[LightGBM] [Info] Start training from score -1.936120\n",
      "[LightGBM] [Info] Start training from score -1.944753\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3072\n",
      "[LightGBM] [Info] Number of data points in the train set: 12096, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -1.937267\n",
      "[LightGBM] [Info] Start training from score -1.933831\n",
      "[LightGBM] [Info] Start training from score -1.966373\n",
      "[LightGBM] [Info] Start training from score -1.955797\n",
      "[LightGBM] [Info] Start training from score -1.935547\n",
      "[LightGBM] [Info] Start training from score -1.947648\n",
      "[LightGBM] [Info] Start training from score -1.945332\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3070\n",
      "[LightGBM] [Info] Number of data points in the train set: 12096, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -1.953462\n",
      "[LightGBM] [Info] Start training from score -1.949969\n",
      "[LightGBM] [Info] Start training from score -1.958137\n",
      "[LightGBM] [Info] Start training from score -1.933259\n",
      "[LightGBM] [Info] Start training from score -1.947068\n",
      "[LightGBM] [Info] Start training from score -1.940140\n",
      "[LightGBM] [Info] Start training from score -1.939565\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3076\n",
      "[LightGBM] [Info] Number of data points in the train set: 12096, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -1.954629\n",
      "[LightGBM] [Info] Start training from score -1.948808\n",
      "[LightGBM] [Info] Start training from score -1.937267\n",
      "[LightGBM] [Info] Start training from score -1.937841\n",
      "[LightGBM] [Info] Start training from score -1.950551\n",
      "[LightGBM] [Info] Start training from score -1.939565\n",
      "[LightGBM] [Info] Start training from score -1.952879\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004816 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3075\n",
      "[LightGBM] [Info] Number of data points in the train set: 12096, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -1.941291\n",
      "[LightGBM] [Info] Start training from score -1.932688\n",
      "[LightGBM] [Info] Start training from score -1.940715\n",
      "[LightGBM] [Info] Start training from score -1.954629\n",
      "[LightGBM] [Info] Start training from score -1.938990\n",
      "[LightGBM] [Info] Start training from score -1.966373\n",
      "[LightGBM] [Info] Start training from score -1.947068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([102.47147298,  89.47145891, 102.27731681,  89.4508431 ,\n",
       "        110.0320859 ]),\n",
       " 'score_time': array([0.139575  , 0.15322113, 0.18612695, 0.10202074, 0.1522522 ]),\n",
       " 'test_accuracy': array([0.87070106, 0.87301587, 0.86871693, 0.87830688, 0.86574074])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Elevation_x_Rawah'] = X['Elevation'] * X['Wilderness_Area1']\n",
    "X['Elevation_x_Neota'] = X['Elevation'] * X['Wilderness_Area2'] \n",
    "X['Elevation_x_Comanche'] = X['Elevation'] * X['Wilderness_Area3']\n",
    "X['Elevation_x_Cache'] = X['Elevation'] * X['Wilderness_Area4']\n",
    "\n",
    "X_test['Elevation_x_Rawah'] = X_test['Elevation'] * X_test['Wilderness_Area1']\n",
    "X_test['Elevation_x_Neota'] = X_test['Elevation'] * X_test['Wilderness_Area2'] \n",
    "X_test['Elevation_x_Comanche'] = X_test['Elevation'] * X_test['Wilderness_Area3']\n",
    "X_test['Elevation_x_Cache'] = X_test['Elevation'] * X_test['Wilderness_Area4']\n",
    "\n",
    "ecologically_inspired_features = ['Elevation_x_Rawah', 'Elevation_x_Neota', 'Elevation_x_Comanche', 'Elevation_x_Cache']\n",
    "training(X[original_features + ecologically_inspired_features], y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0172d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2418\n",
      "[LightGBM] [Info] Number of data points in the train set: 12096, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score -1.943021\n",
      "[LightGBM] [Info] Start training from score -1.964602\n",
      "[LightGBM] [Info] Start training from score -1.927561\n",
      "[LightGBM] [Info] Start training from score -1.948228\n",
      "[LightGBM] [Info] Start training from score -1.957552\n",
      "[LightGBM] [Info] Start training from score -1.936120\n",
      "[LightGBM] [Info] Start training from score -1.944753\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2413\n",
      "[LightGBM] [Info] Number of data points in the train set: 12096, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score -1.937267\n",
      "[LightGBM] [Info] Start training from score -1.933831\n",
      "[LightGBM] [Info] Start training from score -1.966373\n",
      "[LightGBM] [Info] Start training from score -1.955797\n",
      "[LightGBM] [Info] Start training from score -1.935547\n",
      "[LightGBM] [Info] Start training from score -1.947648\n",
      "[LightGBM] [Info] Start training from score -1.945332\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2414\n",
      "[LightGBM] [Info] Number of data points in the train set: 12096, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score -1.953462\n",
      "[LightGBM] [Info] Start training from score -1.949969\n",
      "[LightGBM] [Info] Start training from score -1.958137\n",
      "[LightGBM] [Info] Start training from score -1.933259\n",
      "[LightGBM] [Info] Start training from score -1.947068\n",
      "[LightGBM] [Info] Start training from score -1.940140\n",
      "[LightGBM] [Info] Start training from score -1.939565\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 23\u001b[0m\n\u001b[1;32m     18\u001b[0m X_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNear_Water\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (X_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHorizontal_Distance_To_Hydrology\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m100\u001b[39m) \u001b[38;5;241m&\u001b[39m \\\n\u001b[1;32m     19\u001b[0m                    (\u001b[38;5;28mabs\u001b[39m(X_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVertical_Distance_To_Hydrology\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m     22\u001b[0m distance_to_water_features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEuclidean_Distance_To_Hydrology\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNear_Water\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 23\u001b[0m training(X[original_features \u001b[38;5;241m+\u001b[39m distance_to_water_features], y, model)\n",
      "Cell \u001b[0;32mIn[25], line 6\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(X, y, model, cv)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mTrain a model using cross-validation and display the confusion matrix.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      5\u001b[0m kf \u001b[38;5;241m=\u001b[39m KFold(n_splits\u001b[38;5;241m=\u001b[39mcv, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m scores \u001b[38;5;241m=\u001b[39m cross_validate(model, X, y, cv\u001b[38;5;241m=\u001b[39mkf, scoring\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      7\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m cross_val_predict(model, X, y, cv\u001b[38;5;241m=\u001b[39mkf)\n\u001b[1;32m      8\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y, y_pred)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/model_selection/_validation.py:411\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    410\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 411\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    412\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    413\u001b[0m         clone(estimator),\n\u001b[1;32m    414\u001b[0m         X,\n\u001b[1;32m    415\u001b[0m         y,\n\u001b[1;32m    416\u001b[0m         scorer\u001b[38;5;241m=\u001b[39mscorers,\n\u001b[1;32m    417\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    418\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    419\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    420\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    421\u001b[0m         fit_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit,\n\u001b[1;32m    422\u001b[0m         score_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mscorer\u001b[38;5;241m.\u001b[39mscore,\n\u001b[1;32m    423\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[1;32m    424\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    425\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[1;32m    426\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    427\u001b[0m     )\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m    429\u001b[0m )\n\u001b[1;32m    431\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/model_selection/_validation.py:866\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    864\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 866\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/lightgbm/sklearn.py:1560\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1557\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1558\u001b[0m             valid_sets\u001b[38;5;241m.\u001b[39mappend((valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y)))\n\u001b[0;32m-> 1560\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m   1561\u001b[0m     X,\n\u001b[1;32m   1562\u001b[0m     _y,\n\u001b[1;32m   1563\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1564\u001b[0m     init_score\u001b[38;5;241m=\u001b[39minit_score,\n\u001b[1;32m   1565\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39mvalid_sets,\n\u001b[1;32m   1566\u001b[0m     eval_names\u001b[38;5;241m=\u001b[39meval_names,\n\u001b[1;32m   1567\u001b[0m     eval_sample_weight\u001b[38;5;241m=\u001b[39meval_sample_weight,\n\u001b[1;32m   1568\u001b[0m     eval_class_weight\u001b[38;5;241m=\u001b[39meval_class_weight,\n\u001b[1;32m   1569\u001b[0m     eval_init_score\u001b[38;5;241m=\u001b[39meval_init_score,\n\u001b[1;32m   1570\u001b[0m     eval_metric\u001b[38;5;241m=\u001b[39meval_metric,\n\u001b[1;32m   1571\u001b[0m     feature_name\u001b[38;5;241m=\u001b[39mfeature_name,\n\u001b[1;32m   1572\u001b[0m     categorical_feature\u001b[38;5;241m=\u001b[39mcategorical_feature,\n\u001b[1;32m   1573\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m   1574\u001b[0m     init_model\u001b[38;5;241m=\u001b[39minit_model,\n\u001b[1;32m   1575\u001b[0m )\n\u001b[1;32m   1576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/lightgbm/sklearn.py:1049\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1046\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1047\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m-> 1049\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[1;32m   1050\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m   1051\u001b[0m     train_set\u001b[38;5;241m=\u001b[39mtrain_set,\n\u001b[1;32m   1052\u001b[0m     num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators,\n\u001b[1;32m   1053\u001b[0m     valid_sets\u001b[38;5;241m=\u001b[39mvalid_sets,\n\u001b[1;32m   1054\u001b[0m     valid_names\u001b[38;5;241m=\u001b[39meval_names,\n\u001b[1;32m   1055\u001b[0m     feval\u001b[38;5;241m=\u001b[39meval_metrics_callable,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m     init_model\u001b[38;5;241m=\u001b[39minit_model,\n\u001b[1;32m   1057\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m   1058\u001b[0m )\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mnum_feature()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/lightgbm/engine.py:322\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    311\u001b[0m     cb(\n\u001b[1;32m    312\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[1;32m    313\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    319\u001b[0m         )\n\u001b[1;32m    320\u001b[0m     )\n\u001b[0;32m--> 322\u001b[0m booster\u001b[38;5;241m.\u001b[39mupdate(fobj\u001b[38;5;241m=\u001b[39mfobj)\n\u001b[1;32m    324\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/lightgbm/basic.py:4155\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   4152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   4153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4154\u001b[0m _safe_call(\n\u001b[0;32m-> 4155\u001b[0m     _LIB\u001b[38;5;241m.\u001b[39mLGBM_BoosterUpdateOneIter(\n\u001b[1;32m   4156\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle,\n\u001b[1;32m   4157\u001b[0m         ctypes\u001b[38;5;241m.\u001b[39mbyref(is_finished),\n\u001b[1;32m   4158\u001b[0m     )\n\u001b[1;32m   4159\u001b[0m )\n\u001b[1;32m   4160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   4161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Euclidean distance to water (hypotenuse of horizontal and vertical)\n",
    "X['Euclidean_Distance_To_Hydrology'] = np.sqrt(\n",
    "    X['Horizontal_Distance_To_Hydrology']**2 + \n",
    "    X['Vertical_Distance_To_Hydrology']**2\n",
    ")\n",
    "\n",
    "# Water presence flag (areas near water)\n",
    "X['Near_Water'] = (X['Horizontal_Distance_To_Hydrology'] < 100) & \\\n",
    "                   (abs(X['Vertical_Distance_To_Hydrology']) < 20)\n",
    "            \n",
    "            \n",
    "X_test['Euclidean_Distance_To_Hydrology'] = np.sqrt(\n",
    "    X_test['Horizontal_Distance_To_Hydrology']**2 + \n",
    "    X_test['Vertical_Distance_To_Hydrology']**2\n",
    ")\n",
    "\n",
    "# Water presence flag (areas near water)\n",
    "X_test['Near_Water'] = (X_test['Horizontal_Distance_To_Hydrology'] < 100) & \\\n",
    "                   (abs(X_test['Vertical_Distance_To_Hydrology']) < 20)\n",
    "                   \n",
    "                                      \n",
    "distance_to_water_features = ['Euclidean_Distance_To_Hydrology', 'Near_Water']\n",
    "training(X[original_features + distance_to_water_features], y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00283335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.93779421, 1.94208097, 2.03963733, 2.07097602, 2.11590219]),\n",
       " 'score_time': array([0.04826975, 0.04885006, 0.04234982, 0.06409907, 0.06104684]),\n",
       " 'test_accuracy': array([0.84953704, 0.84722222, 0.83994709, 0.84623016, 0.83630952])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Roughness - difference between hillshade times\n",
    "X['Hillshade_Range'] = X['Hillshade_3pm'] - X['Hillshade_9am']\n",
    "X['Hillshade_Variance'] = X[['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']].var(axis=1)\n",
    "\n",
    "# Slope-aspect interaction (northness/eastness)\n",
    "X['Northness'] = np.cos(np.radians(X['Aspect']))\n",
    "X['Eastness'] = np.sin(np.radians(X['Aspect']))\n",
    "X['Slope_x_Northness'] = X['Slope'] * X['Northness']\n",
    "\n",
    "# Roughness - difference between hillshade times\n",
    "X_test['Hillshade_Range'] = X_test['Hillshade_3pm'] - X_test['Hillshade_9am']\n",
    "X_test['Hillshade_Variance'] = X_test[['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']].var(axis=1)\n",
    "\n",
    "# Slope-aspect interaction (northness/eastness)\n",
    "X_test['Northness'] = np.cos(np.radians(X['Aspect']))\n",
    "X_test['Eastness'] = np.sin(np.radians(X['Aspect']))\n",
    "X_test['Slope_x_Northness'] = X_test['Slope'] * X_test['Northness']\n",
    "\n",
    "terrain_features = ['Hillshade_Range', 'Hillshade_Variance', 'Slope_x_Northness']\n",
    "training(X[original_features + terrain_features], y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6fad40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.83420396, 1.91341901, 1.86388087, 1.90320206, 1.86558604]),\n",
       " 'score_time': array([0.04879403, 0.05395389, 0.03824615, 0.0596869 , 0.06841683]),\n",
       " 'test_accuracy': array([0.87202381, 0.86474868, 0.87367725, 0.86441799, 0.8667328 ])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Roads vs Fire points ratio (different access patterns)\n",
    "X['Road_to_Fire_Ratio'] = X['Horizontal_Distance_To_Roadways'] / \\\n",
    "                           (X['Horizontal_Distance_To_Fire_Points'] + 1)\n",
    "\n",
    "# Hydrology to Roads ratio\n",
    "X['Hydro_to_Roads_Ratio'] = X['Horizontal_Distance_To_Hydrology'] / \\\n",
    "                             (X['Horizontal_Distance_To_Roadways'] + 1)\n",
    "\n",
    "# Roads vs Fire points ratio (different access patterns)\n",
    "X_test['Road_to_Fire_Ratio'] = X_test['Horizontal_Distance_To_Roadways'] / \\\n",
    "                           (X_test['Horizontal_Distance_To_Fire_Points'] + 1)\n",
    "\n",
    "# Hydrology to Roads ratio\n",
    "X_test['Hydro_to_Roads_Ratio'] = X_test['Horizontal_Distance_To_Hydrology'] / \\\n",
    "                             (X_test['Horizontal_Distance_To_Roadways'] + 1)\n",
    "                             \n",
    "distance_ratio_features = ['Road_to_Fire_Ratio', 'Hydro_to_Roads_Ratio']\n",
    "training(X[original_features + distance_ratio_features], y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0e93c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.18482089, 1.71275306, 1.69264007, 1.72865605, 1.68879008]),\n",
       " 'score_time': array([0.06128407, 0.06958294, 0.06088996, 0.05559993, 0.0492332 ]),\n",
       " 'test_accuracy': array([0.85945767, 0.85912698, 0.85350529, 0.85582011, 0.84854497])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create elevation bands based on ecological knowledge\n",
    "def elevation_zone(elev):\n",
    "    if elev < 2750:\n",
    "        return 'low'  # Ponderosa, Douglas-fir\n",
    "    elif elev < 3000:\n",
    "        return 'mid_low'  # Lodgepole\n",
    "    elif elev < 3250:\n",
    "        return 'mid_high'  # Spruce/Fir transition\n",
    "    else:\n",
    "        return 'high'  # Spruce/Fir, Krummholz\n",
    "\n",
    "X['Elevation_Zone'] = X['Elevation'].apply(elevation_zone)\n",
    "X = pd.get_dummies(X, columns=['Elevation_Zone'])\n",
    "\n",
    "X_test['Elevation_Zone'] = X_test['Elevation'].apply(elevation_zone)\n",
    "X_test = pd.get_dummies(X_test, columns=['Elevation_Zone'])\n",
    "\n",
    "eco_zones = [col for col in X.columns if col.startswith('Elevation_Zone_')]\n",
    "training(X[original_features + eco_zones], y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6f90cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.73787284, 1.68141913, 1.63522196, 1.67118692, 1.71046782]),\n",
       " 'score_time': array([0.05363393, 0.05449891, 0.05522418, 0.05496502, 0.04920387]),\n",
       " 'test_accuracy': array([0.86177249, 0.86210317, 0.85515873, 0.86276455, 0.85284392])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "soil_climatic_zones = {\n",
    "    1: 'lower_montane_dry', 2: 'lower_montane', 3: 'montane_dry',\n",
    "    4: 'montane', 5: 'montane_mixed', 6: 'montane_subalpine',\n",
    "    7: 'subalpine', 8: 'alpine'\n",
    "}\n",
    "\n",
    "def soil_idx(col):\n",
    "    m = re.search(r'(\\d+)$', col)   # last digits\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "soil_cols_all = [c for c in X.columns if c.startswith('Soil_Type')]\n",
    "\n",
    "for zone_num, zone_name in soil_climatic_zones.items():\n",
    "    zone_cols = [\n",
    "        c for c in soil_cols_all\n",
    "        if (soil_idx(c) is not None) and (soil_idx(c) // 1000 == zone_num)\n",
    "    ]\n",
    "    if zone_cols:\n",
    "        X[f'Climatic_Zone_{zone_name}'] = X[zone_cols].any(axis=1).astype(int)\n",
    "\n",
    "soil_type_features = [c for c in X.columns if c.startswith('Climatic_Zone_')]\n",
    "\n",
    "training(X[original_features + soil_type_features], y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45733d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.99421191, 1.98575687, 1.9859879 , 1.93806601, 1.97938395]),\n",
       " 'score_time': array([0.05921412, 0.0624609 , 0.065727  , 0.04337215, 0.04552293]),\n",
       " 'test_accuracy': array([0.8667328 , 0.86607143, 0.86111111, 0.86474868, 0.85978836])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# High elevation + specific aspects (Spruce/Fir prefer north aspects)\n",
    "X['High_North'] = (X['Elevation'] > 3000) & (X['Northness'] > 0.5)\n",
    "\n",
    "# Distance to roads + fire points (managed vs natural areas)\n",
    "X['Remote_Index'] = (X['Horizontal_Distance_To_Roadways'] + \n",
    "                      X['Horizontal_Distance_To_Fire_Points']) / 2\n",
    "\n",
    "# Slope position index\n",
    "X['Slope_Position'] = X['Elevation'] * X['Slope'] / 1000\n",
    "\n",
    "# High elevation + specific aspects (Spruce/Fir prefer north aspects)\n",
    "X_test['High_North'] = (X_test['Elevation'] > 3000) & (X_test['Northness'] > 0.5)\n",
    "\n",
    "# Distance to roads + fire points (managed vs natural areas)\n",
    "X_test['Remote_Index'] = (X_test['Horizontal_Distance_To_Roadways'] + \n",
    "                      X_test['Horizontal_Distance_To_Fire_Points']) / 2\n",
    "\n",
    "# Slope position index\n",
    "X_test['Slope_Position'] = X_test['Elevation'] * X_test['Slope'] / 1000\n",
    "\n",
    "complex_features = ['High_North', 'Remote_Index', 'Slope_Position']\n",
    "training(X[original_features + complex_features], y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7973ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# # Select features that show some correlation\n",
    "# key_features = ['Elevation', 'Aspect', 'Slope', \n",
    "#                 'Horizontal_Distance_To_Hydrology',\n",
    "#                 'Horizontal_Distance_To_Roadways']\n",
    "\n",
    "# # Create interaction terms up to degree 2\n",
    "# poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)\n",
    "# poly_features = poly.fit_transform(X[key_features])\n",
    "\n",
    "# poly_feature_names = poly.get_feature_names_out(key_features)\n",
    "# poly_df = pd.DataFrame(poly_features, columns=poly_feature_names)\n",
    "# X_poly = pd.concat([X.reset_index(drop=True), poly_df], axis=1)\n",
    "# training(X_poly[original_features + list(poly_feature_names)], y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4740a90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the iteraction of the different groups and getting the best combination of features\n",
    "\n",
    "all_features = original_features + ecologically_inspired_features + distance_to_water_features + terrain_features + distance_ratio_features + eco_zones + soil_type_features + complex_features #+ list(poly_feature_names)\n",
    "# training(X_poly[all_features], y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b000721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept Elevation: baseline 0.8644 -> 0.8579\n",
      "Pruned Aspect: baseline 0.8644 -> 0.8653\n",
      "Pruned Slope: baseline 0.8653 -> 0.8668\n",
      "Pruned Horizontal_Distance_To_Hydrology: baseline 0.8668 -> 0.8693\n",
      "Kept Vertical_Distance_To_Hydrology: baseline 0.8693 -> 0.8685\n",
      "Kept Horizontal_Distance_To_Roadways: baseline 0.8693 -> 0.8606\n",
      "Pruned Hillshade_9am: baseline 0.8693 -> 0.8718\n",
      "Pruned Hillshade_Noon: baseline 0.8718 -> 0.8717\n",
      "Pruned Hillshade_3pm: baseline 0.8717 -> 0.8729\n",
      "Kept Horizontal_Distance_To_Fire_Points: baseline 0.8729 -> 0.8690\n",
      "Pruned Wilderness_Area1: baseline 0.8729 -> 0.8739\n",
      "Pruned Wilderness_Area2: baseline 0.8739 -> 0.8741\n",
      "Pruned Wilderness_Area3: baseline 0.8741 -> 0.8742\n",
      "Kept Wilderness_Area4: baseline 0.8742 -> 0.8731\n",
      "Kept Soil_Type1: baseline 0.8742 -> 0.8722\n",
      "Kept Soil_Type2: baseline 0.8742 -> 0.8711\n",
      "Kept Soil_Type3: baseline 0.8742 -> 0.8708\n",
      "Kept Soil_Type4: baseline 0.8742 -> 0.8736\n",
      "Kept Soil_Type5: baseline 0.8742 -> 0.8729\n",
      "Kept Soil_Type6: baseline 0.8742 -> 0.8702\n",
      "Kept Soil_Type7: baseline 0.8742 -> 0.8733\n",
      "Kept Soil_Type8: baseline 0.8742 -> 0.8734\n",
      "Kept Soil_Type9: baseline 0.8742 -> 0.8724\n",
      "Kept Soil_Type10: baseline 0.8742 -> 0.8725\n",
      "Kept Soil_Type11: baseline 0.8742 -> 0.8732\n",
      "Pruned Soil_Type12: baseline 0.8742 -> 0.8741\n",
      "Kept Soil_Type13: baseline 0.8741 -> 0.8726\n",
      "Kept Soil_Type14: baseline 0.8741 -> 0.8713\n",
      "Kept Soil_Type15: baseline 0.8741 -> 0.8728\n",
      "Kept Soil_Type16: baseline 0.8741 -> 0.8730\n",
      "Kept Soil_Type17: baseline 0.8741 -> 0.8727\n",
      "Pruned Soil_Type18: baseline 0.8741 -> 0.8739\n",
      "Kept Soil_Type19: baseline 0.8739 -> 0.8728\n",
      "Kept Soil_Type20: baseline 0.8739 -> 0.8724\n",
      "Kept Soil_Type21: baseline 0.8739 -> 0.8722\n",
      "Kept Soil_Type22: baseline 0.8739 -> 0.8718\n",
      "Kept Soil_Type23: baseline 0.8739 -> 0.8724\n",
      "Pruned Soil_Type24: baseline 0.8739 -> 0.8738\n",
      "Kept Soil_Type25: baseline 0.8738 -> 0.8724\n",
      "Pruned Soil_Type26: baseline 0.8738 -> 0.8735\n",
      "Pruned Soil_Type27: baseline 0.8735 -> 0.8753\n",
      "Kept Soil_Type28: baseline 0.8753 -> 0.8730\n",
      "Kept Soil_Type29: baseline 0.8753 -> 0.8724\n",
      "Kept Soil_Type30: baseline 0.8753 -> 0.8733\n",
      "Kept Soil_Type31: baseline 0.8753 -> 0.8744\n",
      "Kept Soil_Type32: baseline 0.8753 -> 0.8731\n",
      "Kept Soil_Type33: baseline 0.8753 -> 0.8714\n",
      "Kept Soil_Type34: baseline 0.8753 -> 0.8731\n",
      "Kept Soil_Type35: baseline 0.8753 -> 0.8734\n",
      "Kept Soil_Type36: baseline 0.8753 -> 0.8739\n",
      "Kept Soil_Type37: baseline 0.8753 -> 0.8728\n",
      "Kept Soil_Type38: baseline 0.8753 -> 0.8745\n",
      "Kept Soil_Type39: baseline 0.8753 -> 0.8729\n",
      "Kept Soil_Type40: baseline 0.8753 -> 0.8724\n",
      "Kept Elevation_x_Rawah: baseline 0.8753 -> 0.8726\n",
      "Kept Elevation_x_Neota: baseline 0.8753 -> 0.8718\n",
      "Kept Elevation_x_Comanche: baseline 0.8753 -> 0.8704\n",
      "Kept Elevation_x_Cache: baseline 0.8753 -> 0.8706\n",
      "Kept Euclidean_Distance_To_Hydrology: baseline 0.8753 -> 0.8738\n",
      "Pruned Near_Water: baseline 0.8753 -> 0.8762\n",
      "Kept Hillshade_Range: baseline 0.8762 -> 0.8731\n",
      "Kept Hillshade_Variance: baseline 0.8762 -> 0.8752\n",
      "Kept Slope_x_Northness: baseline 0.8762 -> 0.8724\n",
      "Kept Road_to_Fire_Ratio: baseline 0.8762 -> 0.8710\n",
      "Kept Hydro_to_Roads_Ratio: baseline 0.8762 -> 0.8731\n",
      "Kept Elevation_Zone_high: baseline 0.8762 -> 0.8729\n",
      "Kept Elevation_Zone_low: baseline 0.8762 -> 0.8737\n",
      "Kept Elevation_Zone_mid_high: baseline 0.8762 -> 0.8747\n",
      "Kept Elevation_Zone_mid_low: baseline 0.8762 -> 0.8738\n",
      "Kept High_North: baseline 0.8762 -> 0.8748\n",
      "Kept Remote_Index: baseline 0.8762 -> 0.8652\n",
      "Kept Slope_Position: baseline 0.8762 -> 0.8745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([2.09004283, 2.06627584, 2.05960584, 2.03395891, 1.98646784]),\n",
       " 'score_time': array([0.04819202, 0.03687501, 0.03866529, 0.04639387, 0.03939509]),\n",
       " 'test_accuracy': array([0.87863757, 0.87202381, 0.87466931, 0.88293651, 0.87268519])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prune_features(X, y, features, train_func, model, tol=0.0005):\n",
    "    '''\n",
    "    Function to iteratively prune features based on their importance and the impact on model performance.\n",
    "     - X: feature dataframe\n",
    "     - y: target variable\n",
    "     - features: list of features to consider\n",
    "     - train_func: function to train the model and return performance metric\n",
    "     - model: the model to train\n",
    "     - tol: tolerance for performance drop to consider a feature as non-essential\n",
    "     Returns a pruned list of features that contribute most to the model's performance.\n",
    "    '''\n",
    "    baseline_scores = train_func(X[features], y, model)\n",
    "    baseline_score = np.mean(baseline_scores['test_accuracy'])\n",
    "    pruned_features = features.copy()\n",
    "    \n",
    "    for feature in features:\n",
    "        temp_features = [f for f in pruned_features if f != feature]\n",
    "        temp_scores = train_func(X[temp_features], y, model)\n",
    "        temp_score = np.mean(temp_scores['test_accuracy'])\n",
    "        \n",
    "        # If removing the feature does not significantly drop performance, prune it\n",
    "        if baseline_score - temp_score < tol:\n",
    "            pruned_features.remove(feature)\n",
    "            print(f\"Pruned {feature}: baseline {baseline_score:.4f} -> {temp_score:.4f}\")\n",
    "            baseline_score = temp_score  # Update baseline score for next iteration\n",
    "        else:\n",
    "            print(f\"Kept {feature}: baseline {baseline_score:.4f} -> {temp_score:.4f}\")\n",
    "    \n",
    "    return pruned_features\n",
    "    \n",
    "pruned_features = prune_features(X, y, all_features, training, model, tol=0.0005)\n",
    "\n",
    "training(X[pruned_features], y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e1e10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elevation',\n",
       " 'Vertical_Distance_To_Hydrology',\n",
       " 'Horizontal_Distance_To_Roadways',\n",
       " 'Horizontal_Distance_To_Fire_Points',\n",
       " 'Wilderness_Area4',\n",
       " 'Soil_Type1',\n",
       " 'Soil_Type2',\n",
       " 'Soil_Type3',\n",
       " 'Soil_Type4',\n",
       " 'Soil_Type5',\n",
       " 'Soil_Type6',\n",
       " 'Soil_Type7',\n",
       " 'Soil_Type8',\n",
       " 'Soil_Type9',\n",
       " 'Soil_Type10',\n",
       " 'Soil_Type11',\n",
       " 'Soil_Type13',\n",
       " 'Soil_Type14',\n",
       " 'Soil_Type15',\n",
       " 'Soil_Type16',\n",
       " 'Soil_Type17',\n",
       " 'Soil_Type19',\n",
       " 'Soil_Type20',\n",
       " 'Soil_Type21',\n",
       " 'Soil_Type22',\n",
       " 'Soil_Type23',\n",
       " 'Soil_Type25',\n",
       " 'Soil_Type28',\n",
       " 'Soil_Type29',\n",
       " 'Soil_Type30',\n",
       " 'Soil_Type31',\n",
       " 'Soil_Type32',\n",
       " 'Soil_Type33',\n",
       " 'Soil_Type34',\n",
       " 'Soil_Type35',\n",
       " 'Soil_Type36',\n",
       " 'Soil_Type37',\n",
       " 'Soil_Type38',\n",
       " 'Soil_Type39',\n",
       " 'Soil_Type40',\n",
       " 'Elevation_x_Rawah',\n",
       " 'Elevation_x_Neota',\n",
       " 'Elevation_x_Comanche',\n",
       " 'Elevation_x_Cache',\n",
       " 'Euclidean_Distance_To_Hydrology',\n",
       " 'Hillshade_Range',\n",
       " 'Hillshade_Variance',\n",
       " 'Slope_x_Northness',\n",
       " 'Road_to_Fire_Ratio',\n",
       " 'Hydro_to_Roads_Ratio',\n",
       " 'Elevation_Zone_high',\n",
       " 'Elevation_Zone_low',\n",
       " 'Elevation_Zone_mid_high',\n",
       " 'Elevation_Zone_mid_low',\n",
       " 'High_North',\n",
       " 'Remote_Index',\n",
       " 'Slope_Position']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7011bc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pruned_features, columns=[\"features\"])\n",
    "df.to_csv(\"engineenered_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eeee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Cover_Type'] = y\n",
    "X['Id'] = id\n",
    "X['Id' + pruned_features + 'Cover_Type'].to_csv('new_training', index=False)\n",
    "\n",
    "X_test['Id'] = id_test\n",
    "X_test['Id' + pruned_features].to_csv('new_test', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
