{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a56d7f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_validate, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0602482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(X, y, model, cv=5):\n",
    "    '''\n",
    "    Train a model using cross-validation and display the confusion matrix.\n",
    "    '''\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    scores = cross_validate(model, X, y, cv=kf, scoring=['accuracy'])\n",
    "    y_pred = cross_val_predict(model, X, y, cv=kf)\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    # disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    # disp.plot()\n",
    "    # plt.show()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d5713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Data/train.csv')\n",
    "test = pd.read_csv('Data/test-full.csv')\n",
    "X = train.drop(columns=['Id', 'Cover_Type'])\n",
    "\n",
    "X_test = test.drop(columns=['Id'])\n",
    "\n",
    "original_features = X.columns.tolist()\n",
    "y = train['Cover_Type']\n",
    "id = train['Id']\n",
    "id_test = test['Id']\n",
    "\n",
    "model = model = LGBMClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "training(X, y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cb3174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.71755314, 1.70356226, 1.68134713, 1.66542816, 1.69877291]),\n",
       " 'score_time': array([0.05860376, 0.06065059, 0.05434108, 0.05736089, 0.0426271 ]),\n",
       " 'test_accuracy': array([0.86309524, 0.85978836, 0.85615079, 0.87070106, 0.85548942])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Elevation_x_Rawah'] = X['Elevation'] * X['Wilderness_Area1']\n",
    "X['Elevation_x_Neota'] = X['Elevation'] * X['Wilderness_Area2'] \n",
    "X['Elevation_x_Comanche'] = X['Elevation'] * X['Wilderness_Area3']\n",
    "X['Elevation_x_Cache'] = X['Elevation'] * X['Wilderness_Area4']\n",
    "\n",
    "X_test['Elevation_x_Rawah'] = X_test['Elevation'] * X_test['Wilderness_Area1']\n",
    "X_test['Elevation_x_Neota'] = X_test['Elevation'] * X_test['Wilderness_Area2'] \n",
    "X_test['Elevation_x_Comanche'] = X_test['Elevation'] * X_test['Wilderness_Area3']\n",
    "X_test['Elevation_x_Cache'] = X_test['Elevation'] * X_test['Wilderness_Area4']\n",
    "\n",
    "ecologically_inspired_features = ['Elevation_x_Rawah', 'Elevation_x_Neota', 'Elevation_x_Comanche', 'Elevation_x_Cache']\n",
    "training(X[original_features + ecologically_inspired_features], y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0172d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.79032588, 1.81957388, 1.77166986, 1.81673527, 1.76869607]),\n",
       " 'score_time': array([0.04535818, 0.04163027, 0.04101992, 0.0505507 , 0.05028677]),\n",
       " 'test_accuracy': array([0.86474868, 0.8614418 , 0.8478836 , 0.86044974, 0.85251323])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Euclidean distance to water (hypotenuse of horizontal and vertical)\n",
    "X['Euclidean_Distance_To_Hydrology'] = np.sqrt(\n",
    "    X['Horizontal_Distance_To_Hydrology']**2 + \n",
    "    X['Vertical_Distance_To_Hydrology']**2\n",
    ")\n",
    "\n",
    "# Water presence flag (areas near water)\n",
    "X['Near_Water'] = (X['Horizontal_Distance_To_Hydrology'] < 100) & \\\n",
    "                   (abs(X['Vertical_Distance_To_Hydrology']) < 20)\n",
    "            \n",
    "            \n",
    "X_test['Euclidean_Distance_To_Hydrology'] = np.sqrt(\n",
    "    X_test['Horizontal_Distance_To_Hydrology']**2 + \n",
    "    X_test['Vertical_Distance_To_Hydrology']**2\n",
    ")\n",
    "\n",
    "# Water presence flag (areas near water)\n",
    "X_test['Near_Water'] = (X_test['Horizontal_Distance_To_Hydrology'] < 100) & \\\n",
    "                   (abs(X_test['Vertical_Distance_To_Hydrology']) < 20)\n",
    "                   \n",
    "                                      \n",
    "distance_to_water_features = ['Euclidean_Distance_To_Hydrology', 'Near_Water']\n",
    "training(X[original_features + distance_to_water_features], y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00283335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.93779421, 1.94208097, 2.03963733, 2.07097602, 2.11590219]),\n",
       " 'score_time': array([0.04826975, 0.04885006, 0.04234982, 0.06409907, 0.06104684]),\n",
       " 'test_accuracy': array([0.84953704, 0.84722222, 0.83994709, 0.84623016, 0.83630952])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Roughness - difference between hillshade times\n",
    "X['Hillshade_Range'] = X['Hillshade_3pm'] - X['Hillshade_9am']\n",
    "X['Hillshade_Variance'] = X[['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']].var(axis=1)\n",
    "\n",
    "# Slope-aspect interaction (northness/eastness)\n",
    "X['Northness'] = np.cos(np.radians(X['Aspect']))\n",
    "X['Eastness'] = np.sin(np.radians(X['Aspect']))\n",
    "X['Slope_x_Northness'] = X['Slope'] * X['Northness']\n",
    "\n",
    "# Roughness - difference between hillshade times\n",
    "X_test['Hillshade_Range'] = X_test['Hillshade_3pm'] - X_test['Hillshade_9am']\n",
    "X_test['Hillshade_Variance'] = X_test[['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']].var(axis=1)\n",
    "\n",
    "# Slope-aspect interaction (northness/eastness)\n",
    "X_test['Northness'] = np.cos(np.radians(X['Aspect']))\n",
    "X_test['Eastness'] = np.sin(np.radians(X['Aspect']))\n",
    "X_test['Slope_x_Northness'] = X_test['Slope'] * X_test['Northness']\n",
    "\n",
    "terrain_features = ['Hillshade_Range', 'Hillshade_Variance', 'Slope_x_Northness']\n",
    "training(X[original_features + terrain_features], y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6fad40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.83420396, 1.91341901, 1.86388087, 1.90320206, 1.86558604]),\n",
       " 'score_time': array([0.04879403, 0.05395389, 0.03824615, 0.0596869 , 0.06841683]),\n",
       " 'test_accuracy': array([0.87202381, 0.86474868, 0.87367725, 0.86441799, 0.8667328 ])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Roads vs Fire points ratio (different access patterns)\n",
    "X['Road_to_Fire_Ratio'] = X['Horizontal_Distance_To_Roadways'] / \\\n",
    "                           (X['Horizontal_Distance_To_Fire_Points'] + 1)\n",
    "\n",
    "# Hydrology to Roads ratio\n",
    "X['Hydro_to_Roads_Ratio'] = X['Horizontal_Distance_To_Hydrology'] / \\\n",
    "                             (X['Horizontal_Distance_To_Roadways'] + 1)\n",
    "\n",
    "# Roads vs Fire points ratio (different access patterns)\n",
    "X_test['Road_to_Fire_Ratio'] = X_test['Horizontal_Distance_To_Roadways'] / \\\n",
    "                           (X_test['Horizontal_Distance_To_Fire_Points'] + 1)\n",
    "\n",
    "# Hydrology to Roads ratio\n",
    "X_test['Hydro_to_Roads_Ratio'] = X_test['Horizontal_Distance_To_Hydrology'] / \\\n",
    "                             (X_test['Horizontal_Distance_To_Roadways'] + 1)\n",
    "                             \n",
    "distance_ratio_features = ['Road_to_Fire_Ratio', 'Hydro_to_Roads_Ratio']\n",
    "training(X[original_features + distance_ratio_features], y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0e93c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.18482089, 1.71275306, 1.69264007, 1.72865605, 1.68879008]),\n",
       " 'score_time': array([0.06128407, 0.06958294, 0.06088996, 0.05559993, 0.0492332 ]),\n",
       " 'test_accuracy': array([0.85945767, 0.85912698, 0.85350529, 0.85582011, 0.84854497])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create elevation bands based on ecological knowledge\n",
    "def elevation_zone(elev):\n",
    "    if elev < 2750:\n",
    "        return 'low'  # Ponderosa, Douglas-fir\n",
    "    elif elev < 3000:\n",
    "        return 'mid_low'  # Lodgepole\n",
    "    elif elev < 3250:\n",
    "        return 'mid_high'  # Spruce/Fir transition\n",
    "    else:\n",
    "        return 'high'  # Spruce/Fir, Krummholz\n",
    "\n",
    "X['Elevation_Zone'] = X['Elevation'].apply(elevation_zone)\n",
    "X = pd.get_dummies(X, columns=['Elevation_Zone'])\n",
    "\n",
    "X_test['Elevation_Zone'] = X_test['Elevation'].apply(elevation_zone)\n",
    "X_test = pd.get_dummies(X_test, columns=['Elevation_Zone'])\n",
    "\n",
    "eco_zones = [col for col in X.columns if col.startswith('Elevation_Zone_')]\n",
    "training(X[original_features + eco_zones], y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6f90cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.73787284, 1.68141913, 1.63522196, 1.67118692, 1.71046782]),\n",
       " 'score_time': array([0.05363393, 0.05449891, 0.05522418, 0.05496502, 0.04920387]),\n",
       " 'test_accuracy': array([0.86177249, 0.86210317, 0.85515873, 0.86276455, 0.85284392])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "soil_climatic_zones = {\n",
    "    1: 'lower_montane_dry', 2: 'lower_montane', 3: 'montane_dry',\n",
    "    4: 'montane', 5: 'montane_mixed', 6: 'montane_subalpine',\n",
    "    7: 'subalpine', 8: 'alpine'\n",
    "}\n",
    "\n",
    "def soil_idx(col):\n",
    "    m = re.search(r'(\\d+)$', col)   # last digits\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "soil_cols_all = [c for c in X.columns if c.startswith('Soil_Type')]\n",
    "\n",
    "for zone_num, zone_name in soil_climatic_zones.items():\n",
    "    zone_cols = [\n",
    "        c for c in soil_cols_all\n",
    "        if (soil_idx(c) is not None) and (soil_idx(c) // 1000 == zone_num)\n",
    "    ]\n",
    "    if zone_cols:\n",
    "        X[f'Climatic_Zone_{zone_name}'] = X[zone_cols].any(axis=1).astype(int)\n",
    "\n",
    "soil_type_features = [c for c in X.columns if c.startswith('Climatic_Zone_')]\n",
    "\n",
    "training(X[original_features + soil_type_features], y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45733d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.99421191, 1.98575687, 1.9859879 , 1.93806601, 1.97938395]),\n",
       " 'score_time': array([0.05921412, 0.0624609 , 0.065727  , 0.04337215, 0.04552293]),\n",
       " 'test_accuracy': array([0.8667328 , 0.86607143, 0.86111111, 0.86474868, 0.85978836])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# High elevation + specific aspects (Spruce/Fir prefer north aspects)\n",
    "X['High_North'] = (X['Elevation'] > 3000) & (X['Northness'] > 0.5)\n",
    "\n",
    "# Distance to roads + fire points (managed vs natural areas)\n",
    "X['Remote_Index'] = (X['Horizontal_Distance_To_Roadways'] + \n",
    "                      X['Horizontal_Distance_To_Fire_Points']) / 2\n",
    "\n",
    "# Slope position index\n",
    "X['Slope_Position'] = X['Elevation'] * X['Slope'] / 1000\n",
    "\n",
    "# High elevation + specific aspects (Spruce/Fir prefer north aspects)\n",
    "X_test['High_North'] = (X_test['Elevation'] > 3000) & (X_test['Northness'] > 0.5)\n",
    "\n",
    "# Distance to roads + fire points (managed vs natural areas)\n",
    "X_test['Remote_Index'] = (X_test['Horizontal_Distance_To_Roadways'] + \n",
    "                      X_test['Horizontal_Distance_To_Fire_Points']) / 2\n",
    "\n",
    "# Slope position index\n",
    "X_test['Slope_Position'] = X_test['Elevation'] * X_test['Slope'] / 1000\n",
    "\n",
    "complex_features = ['High_North', 'Remote_Index', 'Slope_Position']\n",
    "training(X[original_features + complex_features], y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7973ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# # Select features that show some correlation\n",
    "# key_features = ['Elevation', 'Aspect', 'Slope', \n",
    "#                 'Horizontal_Distance_To_Hydrology',\n",
    "#                 'Horizontal_Distance_To_Roadways']\n",
    "\n",
    "# # Create interaction terms up to degree 2\n",
    "# poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)\n",
    "# poly_features = poly.fit_transform(X[key_features])\n",
    "\n",
    "# poly_feature_names = poly.get_feature_names_out(key_features)\n",
    "# poly_df = pd.DataFrame(poly_features, columns=poly_feature_names)\n",
    "# X_poly = pd.concat([X.reset_index(drop=True), poly_df], axis=1)\n",
    "# training(X_poly[original_features + list(poly_feature_names)], y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4740a90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the iteraction of the different groups and getting the best combination of features\n",
    "\n",
    "all_features = original_features + ecologically_inspired_features + distance_to_water_features + terrain_features + distance_ratio_features + eco_zones + soil_type_features + complex_features #+ list(poly_feature_names)\n",
    "# training(X_poly[all_features], y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b000721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept Elevation: baseline 0.8644 -> 0.8579\n",
      "Pruned Aspect: baseline 0.8644 -> 0.8653\n",
      "Pruned Slope: baseline 0.8653 -> 0.8668\n",
      "Pruned Horizontal_Distance_To_Hydrology: baseline 0.8668 -> 0.8693\n",
      "Kept Vertical_Distance_To_Hydrology: baseline 0.8693 -> 0.8685\n",
      "Kept Horizontal_Distance_To_Roadways: baseline 0.8693 -> 0.8606\n",
      "Pruned Hillshade_9am: baseline 0.8693 -> 0.8718\n",
      "Pruned Hillshade_Noon: baseline 0.8718 -> 0.8717\n",
      "Pruned Hillshade_3pm: baseline 0.8717 -> 0.8729\n",
      "Kept Horizontal_Distance_To_Fire_Points: baseline 0.8729 -> 0.8690\n",
      "Pruned Wilderness_Area1: baseline 0.8729 -> 0.8739\n",
      "Pruned Wilderness_Area2: baseline 0.8739 -> 0.8741\n",
      "Pruned Wilderness_Area3: baseline 0.8741 -> 0.8742\n",
      "Kept Wilderness_Area4: baseline 0.8742 -> 0.8731\n",
      "Kept Soil_Type1: baseline 0.8742 -> 0.8722\n",
      "Kept Soil_Type2: baseline 0.8742 -> 0.8711\n",
      "Kept Soil_Type3: baseline 0.8742 -> 0.8708\n",
      "Kept Soil_Type4: baseline 0.8742 -> 0.8736\n",
      "Kept Soil_Type5: baseline 0.8742 -> 0.8729\n",
      "Kept Soil_Type6: baseline 0.8742 -> 0.8702\n",
      "Kept Soil_Type7: baseline 0.8742 -> 0.8733\n",
      "Kept Soil_Type8: baseline 0.8742 -> 0.8734\n",
      "Kept Soil_Type9: baseline 0.8742 -> 0.8724\n",
      "Kept Soil_Type10: baseline 0.8742 -> 0.8725\n",
      "Kept Soil_Type11: baseline 0.8742 -> 0.8732\n",
      "Pruned Soil_Type12: baseline 0.8742 -> 0.8741\n",
      "Kept Soil_Type13: baseline 0.8741 -> 0.8726\n",
      "Kept Soil_Type14: baseline 0.8741 -> 0.8713\n",
      "Kept Soil_Type15: baseline 0.8741 -> 0.8728\n",
      "Kept Soil_Type16: baseline 0.8741 -> 0.8730\n",
      "Kept Soil_Type17: baseline 0.8741 -> 0.8727\n",
      "Pruned Soil_Type18: baseline 0.8741 -> 0.8739\n",
      "Kept Soil_Type19: baseline 0.8739 -> 0.8728\n",
      "Kept Soil_Type20: baseline 0.8739 -> 0.8724\n",
      "Kept Soil_Type21: baseline 0.8739 -> 0.8722\n",
      "Kept Soil_Type22: baseline 0.8739 -> 0.8718\n",
      "Kept Soil_Type23: baseline 0.8739 -> 0.8724\n",
      "Pruned Soil_Type24: baseline 0.8739 -> 0.8738\n",
      "Kept Soil_Type25: baseline 0.8738 -> 0.8724\n",
      "Pruned Soil_Type26: baseline 0.8738 -> 0.8735\n",
      "Pruned Soil_Type27: baseline 0.8735 -> 0.8753\n",
      "Kept Soil_Type28: baseline 0.8753 -> 0.8730\n",
      "Kept Soil_Type29: baseline 0.8753 -> 0.8724\n",
      "Kept Soil_Type30: baseline 0.8753 -> 0.8733\n",
      "Kept Soil_Type31: baseline 0.8753 -> 0.8744\n",
      "Kept Soil_Type32: baseline 0.8753 -> 0.8731\n",
      "Kept Soil_Type33: baseline 0.8753 -> 0.8714\n",
      "Kept Soil_Type34: baseline 0.8753 -> 0.8731\n",
      "Kept Soil_Type35: baseline 0.8753 -> 0.8734\n",
      "Kept Soil_Type36: baseline 0.8753 -> 0.8739\n",
      "Kept Soil_Type37: baseline 0.8753 -> 0.8728\n",
      "Kept Soil_Type38: baseline 0.8753 -> 0.8745\n",
      "Kept Soil_Type39: baseline 0.8753 -> 0.8729\n",
      "Kept Soil_Type40: baseline 0.8753 -> 0.8724\n",
      "Kept Elevation_x_Rawah: baseline 0.8753 -> 0.8726\n",
      "Kept Elevation_x_Neota: baseline 0.8753 -> 0.8718\n",
      "Kept Elevation_x_Comanche: baseline 0.8753 -> 0.8704\n",
      "Kept Elevation_x_Cache: baseline 0.8753 -> 0.8706\n",
      "Kept Euclidean_Distance_To_Hydrology: baseline 0.8753 -> 0.8738\n",
      "Pruned Near_Water: baseline 0.8753 -> 0.8762\n",
      "Kept Hillshade_Range: baseline 0.8762 -> 0.8731\n",
      "Kept Hillshade_Variance: baseline 0.8762 -> 0.8752\n",
      "Kept Slope_x_Northness: baseline 0.8762 -> 0.8724\n",
      "Kept Road_to_Fire_Ratio: baseline 0.8762 -> 0.8710\n",
      "Kept Hydro_to_Roads_Ratio: baseline 0.8762 -> 0.8731\n",
      "Kept Elevation_Zone_high: baseline 0.8762 -> 0.8729\n",
      "Kept Elevation_Zone_low: baseline 0.8762 -> 0.8737\n",
      "Kept Elevation_Zone_mid_high: baseline 0.8762 -> 0.8747\n",
      "Kept Elevation_Zone_mid_low: baseline 0.8762 -> 0.8738\n",
      "Kept High_North: baseline 0.8762 -> 0.8748\n",
      "Kept Remote_Index: baseline 0.8762 -> 0.8652\n",
      "Kept Slope_Position: baseline 0.8762 -> 0.8745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([2.09004283, 2.06627584, 2.05960584, 2.03395891, 1.98646784]),\n",
       " 'score_time': array([0.04819202, 0.03687501, 0.03866529, 0.04639387, 0.03939509]),\n",
       " 'test_accuracy': array([0.87863757, 0.87202381, 0.87466931, 0.88293651, 0.87268519])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prune_features(X, y, features, train_func, model, tol=0.0005):\n",
    "    '''\n",
    "    Function to iteratively prune features based on their importance and the impact on model performance.\n",
    "     - X: feature dataframe\n",
    "     - y: target variable\n",
    "     - features: list of features to consider\n",
    "     - train_func: function to train the model and return performance metric\n",
    "     - model: the model to train\n",
    "     - tol: tolerance for performance drop to consider a feature as non-essential\n",
    "     Returns a pruned list of features that contribute most to the model's performance.\n",
    "    '''\n",
    "    baseline_scores = train_func(X[features], y, model)\n",
    "    baseline_score = np.mean(baseline_scores['test_accuracy'])\n",
    "    pruned_features = features.copy()\n",
    "    \n",
    "    for feature in features:\n",
    "        temp_features = [f for f in pruned_features if f != feature]\n",
    "        temp_scores = train_func(X[temp_features], y, model)\n",
    "        temp_score = np.mean(temp_scores['test_accuracy'])\n",
    "        \n",
    "        # If removing the feature does not significantly drop performance, prune it\n",
    "        if baseline_score - temp_score < tol:\n",
    "            pruned_features.remove(feature)\n",
    "            print(f\"Pruned {feature}: baseline {baseline_score:.4f} -> {temp_score:.4f}\")\n",
    "            baseline_score = temp_score  # Update baseline score for next iteration\n",
    "        else:\n",
    "            print(f\"Kept {feature}: baseline {baseline_score:.4f} -> {temp_score:.4f}\")\n",
    "    \n",
    "    return pruned_features\n",
    "    \n",
    "pruned_features = prune_features(X, y, all_features, training, model, tol=0.0005)\n",
    "\n",
    "training(X[pruned_features], y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e1e10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elevation',\n",
       " 'Vertical_Distance_To_Hydrology',\n",
       " 'Horizontal_Distance_To_Roadways',\n",
       " 'Horizontal_Distance_To_Fire_Points',\n",
       " 'Wilderness_Area4',\n",
       " 'Soil_Type1',\n",
       " 'Soil_Type2',\n",
       " 'Soil_Type3',\n",
       " 'Soil_Type4',\n",
       " 'Soil_Type5',\n",
       " 'Soil_Type6',\n",
       " 'Soil_Type7',\n",
       " 'Soil_Type8',\n",
       " 'Soil_Type9',\n",
       " 'Soil_Type10',\n",
       " 'Soil_Type11',\n",
       " 'Soil_Type13',\n",
       " 'Soil_Type14',\n",
       " 'Soil_Type15',\n",
       " 'Soil_Type16',\n",
       " 'Soil_Type17',\n",
       " 'Soil_Type19',\n",
       " 'Soil_Type20',\n",
       " 'Soil_Type21',\n",
       " 'Soil_Type22',\n",
       " 'Soil_Type23',\n",
       " 'Soil_Type25',\n",
       " 'Soil_Type28',\n",
       " 'Soil_Type29',\n",
       " 'Soil_Type30',\n",
       " 'Soil_Type31',\n",
       " 'Soil_Type32',\n",
       " 'Soil_Type33',\n",
       " 'Soil_Type34',\n",
       " 'Soil_Type35',\n",
       " 'Soil_Type36',\n",
       " 'Soil_Type37',\n",
       " 'Soil_Type38',\n",
       " 'Soil_Type39',\n",
       " 'Soil_Type40',\n",
       " 'Elevation_x_Rawah',\n",
       " 'Elevation_x_Neota',\n",
       " 'Elevation_x_Comanche',\n",
       " 'Elevation_x_Cache',\n",
       " 'Euclidean_Distance_To_Hydrology',\n",
       " 'Hillshade_Range',\n",
       " 'Hillshade_Variance',\n",
       " 'Slope_x_Northness',\n",
       " 'Road_to_Fire_Ratio',\n",
       " 'Hydro_to_Roads_Ratio',\n",
       " 'Elevation_Zone_high',\n",
       " 'Elevation_Zone_low',\n",
       " 'Elevation_Zone_mid_high',\n",
       " 'Elevation_Zone_mid_low',\n",
       " 'High_North',\n",
       " 'Remote_Index',\n",
       " 'Slope_Position']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7011bc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pruned_features, columns=[\"features\"])\n",
    "df.to_csv(\"engineenered_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eeee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Cover_Type'] = y\n",
    "X['Id'] = id\n",
    "X['Id' + pruned_features + 'Cover_Type'].to_csv('new_training', index=False)\n",
    "\n",
    "X_test['Id'] = id_test\n",
    "X_test['Id' + pruned_features].to_csv('new_test', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
